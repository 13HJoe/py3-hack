import requests
from collections import deque
import re
from urllib.parse import urljoin
from bs4 import BeautifulSoup
import termcolor

class Scanner:
    def __init__(self, url, ignore):
        # maintain login
        self.session = requests.Session()
        self.target = url
        self.ignore_list = ignore
        self.target_links = []
        self.visited = set()

    def extract_hrefs(self, url):
        response = self.session.get(url)
        if not response:
            return None
        response = response.content
        try:
            href_links = re.findall('(?:href=")(.*?)"', response.decode('utf-8'))
            return href_links
        except:
            return []

    def crawl_by_hrefs(self, url=None):
        if url == None:
            url = self.target
        queue = deque([url])
        # BREADTH-FIRST SEARCH 
        while queue:
            node = queue.popleft()
            if node in self.ignore_list:
                continue
            print("[+] " + node)
            refs = self.extract_hrefs(node)
            if not refs:
                continue
            for link in refs:
                link = urljoin(url, link)
                if link not in self.visited:
                    self.visited.add(link)
                    if url not in link:
                        print("[-] External Link ->", link)
                        continue
                    queue.append(link)
                    
        print("[+] Finished Crawling")

    def extract_forms(self, url):
        response = self.session.get(url)
        # BS allows for the extraction of HTML elements and tags from the pages
        parsed_html = BeautifulSoup(response.content)
        # to get elements from parser HTML 
        return parsed_html.findAll("form")

    def submit_form(self, form, value, url):

        # to get attributes from elements
        action = form.get("action")
        post_url = urljoin(url,action)
        method = form.get("method")

        data_dict = {}
        # find input elements
        inputs_list = form.findAll("input")
        for input in inputs_list:
            input_name = input.get("name")
            input_type = input.get("type")
            input_value = input.get("value") # default set to button placeholder
            if input_type == "text":
                input_value = value
            data_dict[input_name] = input_value
        
        if method == "post":
            return self.session.post(post_url, data=data_dict)
        return self.session.get(post_url, params=data_dict)
    
    def run_scanner(self):
        for link in self.target_links:
            forms = self.extract_forms(link)
            for form in forms:
                # test the form for VULNs
                print("[+] Testing form in "+ link)

            if '=' in link:
                print("[+] Testing "+link)

    def test_xss_url(self, url):
        xss_payload = "<sCript>alert('XSS test')</scRipt>"
        url = url.replace("=","="+xss_payload)
        response = self.session.get(url)
        return xss_payload in response.content.decode('utf-8')

    def test_xss_form(self, form, url):
        xss_payload = "<sCript>alert('XSS test')</scRipt>"
        response = self.submit_form(form, xss_payload, url)
        return xss_payload in response.content.decode('utf-8')
